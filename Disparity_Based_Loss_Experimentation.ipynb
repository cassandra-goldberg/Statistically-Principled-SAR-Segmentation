{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egC6Joqw_knv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from tifffile import imread\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from time import process_time\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Honors Project'\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Class"
      ],
      "metadata": {
        "id": "fWSpCuNiNJYe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m7uB2UJAJ44"
      },
      "outputs": [],
      "source": [
        "class PerlinNoiseDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "      self.x = torch.Tensor(x).float()\n",
        "      self.y = torch.Tensor(y).long()\n",
        "\n",
        "      # Take the logarithm of the tensor\n",
        "      self.x = torch.log1p(self.x)\n",
        "\n",
        "      # Normalize the tensor\n",
        "      self.x = (self.x - self.x.mean()) / self.x.std()\n",
        "\n",
        "    def __len__(self):\n",
        "      \"\"\" Gets the number of images in the busses dataset.\n",
        "          Returns:\n",
        "            int : number of unique images in dataset\n",
        "      \"\"\"\n",
        "      return len(self.x)\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "      \"\"\" Given an index, returns an image and its corresponding object bounding\n",
        "          boxes with their associated labels.\n",
        "          Args:\n",
        "            idx (int) : index of busses data to retrieve\n",
        "      \"\"\"\n",
        "      return self.x[ix].to(DEVICE), self.y[ix].to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Metric Function"
      ],
      "metadata": {
        "id": "AbV-UOR4NIGV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcyU5-9EAKjo"
      },
      "outputs": [],
      "source": [
        "def intersectionOverUnion(pred, label, num_classes=2):\n",
        "    \"\"\" Computes intersection over union metric.\n",
        "        Args:\n",
        "          pred (tensor) : predicted segmentation\n",
        "          label (tensor) : ground truth segmentation\n",
        "          num_classes (int) : number of regions in the ground truth/prediction\n",
        "        Returns:\n",
        "          the average intersection over union for the batch\n",
        "    \"\"\"\n",
        "    _, pred = torch.max(pred, 1)\n",
        "\n",
        "    iou_list = []\n",
        "\n",
        "    for cls in range(num_classes):\n",
        "        pred_mask = (pred == cls)\n",
        "        true_mask = (label == cls)\n",
        "\n",
        "        intersection = (pred_mask & true_mask).float().sum((1, 2))\n",
        "        union = (pred_mask | true_mask).float().sum((1, 2))\n",
        "\n",
        "        iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "        iou_list.append(iou.mean().item())\n",
        "\n",
        "    return np.mean(iou_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Metric Function"
      ],
      "metadata": {
        "id": "-HvDvYyEPngH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amDJBIfZ-0un"
      },
      "outputs": [],
      "source": [
        "def AveragePixelLoss(img, pred, target, eucdist_coef=0, ce_coef=1):\n",
        "    \"\"\" Computes the Euclidean distance between the average pixel values of the\n",
        "        perceived regions in the predicted segmentation. Adds this distance to\n",
        "        the standard cross-entropy loss, with coefficients dictating the\n",
        "        relative weight of each component into the final loss.\n",
        "        Args:\n",
        "          img (tensor) : original input image\n",
        "          pred (tensor) : predicted segmentation\n",
        "          target (tensor) : ground truth segmentation\n",
        "          eucdis_coef (int) : weight of Euclidean distance component in final loss\n",
        "          ce_coef (int) : weight of cross-entropy component in final loss\n",
        "        Returns:\n",
        "          loss value corresponding to the batch\n",
        "    \"\"\"\n",
        "    # Regular cross-entropy loss\n",
        "    cel = nn.CrossEntropyLoss()\n",
        "    cross_entropy = cel(pred, target)\n",
        "\n",
        "    # Using averaging\n",
        "    sm = nn.Softmax(dim=1)\n",
        "    pred_softmax = sm(pred)\n",
        "\n",
        "    n_pixels = img.shape[2] * img.shape[3]\n",
        "\n",
        "    # Calculate the average pixel loss\n",
        "    pixel_losses = torch.empty(pred.shape[0])\n",
        "    for batch in range(pred.shape[0]):\n",
        "      m0 = torch.sum(pred_softmax[batch, 0, :, :] * img[batch, 0, :, :]) / n_pixels\n",
        "      m1 = torch.sum(pred_softmax[batch, 1, :, :] * img[batch, 0, :, :]) / n_pixels\n",
        "      pixel_losses[batch] = -((m0 - m1) ** 2)\n",
        "\n",
        "    average_pixel_comp = pixel_losses.mean()\n",
        "\n",
        "    return ce_coef * cross_entropy + euc_dist_coef * average_pixel_comp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_q4yWpPlDfS"
      },
      "source": [
        "Typical U-Net Blocks in U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA4qS106lDAE"
      },
      "outputs": [],
      "source": [
        "class conv_block(nn.Module):\n",
        "    \"\"\" Helper block with convolutions to be used in U-Net.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_c, out_c, kernel_size=3):\n",
        "        super().__init__()\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=kernel_size, padding=padding)\n",
        "        self.bn1 = nn.BatchNorm2d(out_c)\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=kernel_size, padding=padding)\n",
        "        self.bn2 = nn.BatchNorm2d(out_c)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class encoder_block(nn.Module):\n",
        "    \"\"\" Block with learnable convolutions and max pooling layers that is used\n",
        "        to learn feature maps and reduce the spatial dimensions of the input.\n",
        "        To be used in the encoder of a U-Net.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_c, out_c, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.conv = conv_block(in_c, out_c, kernel_size=kernel_size)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        p = self.pool(x)\n",
        "        return x, p\n",
        "\n",
        "\n",
        "class decoder_block(nn.Module):\n",
        "    \"\"\" Block with learnable transpose convolutions and max pooling layers that\n",
        "        is used to reconstruct the original data and increase the spatial\n",
        "        dimensions of the input. To be used in the decoder of a U-Net.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
        "        self.conv = conv_block(out_c+out_c, out_c)\n",
        "        self.conv_noskip = conv_block(out_c, out_c)\n",
        "\n",
        "    def forward(self, inputs, skip):\n",
        "        x = self.up(inputs)\n",
        "        x = torch.cat([x, skip], axis=1)\n",
        "        x = self.conv(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhrXAwqFEymY"
      },
      "outputs": [],
      "source": [
        "class UShape(nn.Module):\n",
        "  \"\"\" Class that can be used for all U-shaped architectures.\n",
        "      Pass in in_c, out_c, encoder block, and decoder block to customize.\n",
        "  \"\"\"\n",
        "  def __init__(self, encoder=encoder_block, decoder=decoder_block, in_c=1, out_c=2, hid1=64, hid2=128, hid3=256, bot=512, drop_p=0.5):\n",
        "    super().__init__()\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    self.e1 = encoder(in_c, hid1)\n",
        "    self.e2 = encoder(hid1, hid2)\n",
        "    self.e3 = encoder(hid2, hid3)\n",
        "    \"\"\" Bottleneck \"\"\"\n",
        "    self.b = nn.Sequential(\n",
        "            conv_block(hid3, bot),\n",
        "            nn.Dropout(drop_p)\n",
        "    )\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    self.d1 = decoder(bot, hid3)\n",
        "    self.d2 = decoder(hid3, hid2)\n",
        "    self.d3 = decoder(hid2, hid1)\n",
        "    \"\"\" Classifier \"\"\"\n",
        "    self.outputs = nn.Conv2d(hid1, out_c, kernel_size=1, padding=0)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1, p1 = self.e1(inputs)\n",
        "    s2, p2 = self.e2(p1)\n",
        "    s3, p3 = self.e3(p2)\n",
        "    \"\"\" Bottleneck \"\"\"\n",
        "    b = self.b(p3)\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = self.d1(b, s3)\n",
        "    d2 = self.d2(d1, s2)\n",
        "    d3 = self.d3(d2, s1)\n",
        "    \"\"\" Classifier \"\"\"\n",
        "    outputs = self.outputs(d3)\n",
        "    return outputs\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ushape = UShape()\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    outputs = self.ushape(inputs)\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeGrHnbPn9G4"
      },
      "source": [
        "Typical U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXWejsHgn-SI"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "  \"\"\" Standard U-Net\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ushape = UShape()\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    outputs = self.ushape(inputs)\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Functions/Classes for Model Running"
      ],
      "metadata": {
        "id": "MY4uobB4OkvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An_VvAwTAPNx"
      },
      "outputs": [],
      "source": [
        "def plot_train_test(training_set, testing_set, plot_type, model_name=\"\"):\n",
        "  \"\"\"\n",
        "  Plots loss over epochs.\n",
        "  \"\"\"\n",
        "  plt.plot(training_set, label = \"Training \" + plot_type)\n",
        "  plt.plot(testing_set, label = \"Testing \" + plot_type)\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(plot_type)\n",
        "  plt.legend()\n",
        "  if model_name:\n",
        "    plt.savefig(f'{base_dir}/Results/Plots/{model_name}_{plot_type}.png')\n",
        "  plt.show()\n",
        "  plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ppJoNCDAfW3"
      },
      "outputs": [],
      "source": [
        "class ModelRunner():\n",
        "  \"\"\"Class for training/testing model\"\"\"\n",
        "  def __init__(self, model, train_dl, test_dl, epochs=70, eucdist_coef=0, ce_coef=1):\n",
        "    \"\"\" Initialized the modelrunner.\n",
        "        Args:\n",
        "          model (Pytorch model) : the U-Net to be trained\n",
        "          train_dl (dataloader) : allows acccess to the training dataset\n",
        "          test_dl (dataloader) : allows acccess to the testing dataset\n",
        "          epochs (int) : the number of times to send the training data through\n",
        "                         the model\n",
        "    \"\"\"\n",
        "    self.LR = 1e-4\n",
        "    self.EPOCHS = epochs\n",
        "    self.optimizer = Adam(model.parameters(), lr=self.LR)\n",
        "\n",
        "    self.model = model.to(DEVICE)\n",
        "    self.train_dl = train_dl\n",
        "    self.test_dl = test_dl\n",
        "\n",
        "    self.training_losses = []\n",
        "    self.testing_losses = []\n",
        "    self.training_ious = []\n",
        "    self.testing_ious = []\n",
        "    self.train_time = 0\n",
        "\n",
        "    self.LOSS_FUNC = UnsupervisedAveragePixelLoss\n",
        "    self.euc_dist_coef = eucdist_coef\n",
        "    self.ce_coef = ce_coef\n",
        "\n",
        "  def train(self, do_print):\n",
        "    \"\"\" Trains the model on the training dataset.\n",
        "    \"\"\"\n",
        "    training_loss_per_epoch = []\n",
        "    training_iou_per_epoch = []\n",
        "\n",
        "    self.model.train()\n",
        "    start_time = process_time()\n",
        "    for data, labels in self.train_dl:\n",
        "      data = data.unsqueeze(1)\n",
        "      labels = labels.clone().detach().long()\n",
        "\n",
        "      self.optimizer.zero_grad()\n",
        "      y_pred = self.model(data)\n",
        "      loss = self.LOSS_FUNC(img, pred, target, eucdist_coef=self.eucdist_coef, ce_coef=self.ce_coef)\n",
        "      iou = intersectionOverUnion(y_pred, labels)\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "      training_loss_per_epoch.append(loss.item())\n",
        "      training_iou_per_epoch.append(iou)\n",
        "\n",
        "    end_time = process_time()\n",
        "    self.train_time += (end_time - start_time)\n",
        "\n",
        "    avg_loss = np.mean(training_loss_per_epoch)\n",
        "    avg_iou = np.mean(training_iou_per_epoch)\n",
        "    self.training_losses.append(avg_loss)\n",
        "    self.training_ious.append(avg_iou)\n",
        "    if do_print:\n",
        "        print(\"avg train loss (Unsupervised Average Pixel Loss):\", avg_loss)\n",
        "        print(\"avg train IOU:\", avg_iou)\n",
        "\n",
        "  def test(self, do_print):\n",
        "    \"\"\" Tests the model on the testing dataset.\n",
        "    \"\"\"\n",
        "    testing_loss_per_epoch = []\n",
        "    testing_iou_per_epoch = []\n",
        "    self.model.eval()\n",
        "    for data, labels in self.test_dl:\n",
        "      data = data.unsqueeze(1)\n",
        "      labels = labels.clone().detach().long()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        y_pred = self.model(data)\n",
        "\n",
        "        loss = self.LOSS_FUNC(img, pred, target, eucdist_coef=self.eucdist_coef, ce_coef=self.ce_coef)\n",
        "\n",
        "        iou = intersectionOverUnion(y_pred, labels)\n",
        "        testing_iou_per_epoch.append(iou)\n",
        "        testing_loss_per_epoch.append(loss.item())\n",
        "\n",
        "    avg_loss = np.mean(testing_loss_per_epoch)\n",
        "    avg_iou = np.mean(testing_iou_per_epoch)\n",
        "    self.testing_losses.append(avg_loss)\n",
        "    self.testing_ious.append(avg_iou)\n",
        "    if do_print:\n",
        "        print(\"avg test loss (Unsupervised Average Pixel):\", avg_loss)\n",
        "        print(\"avg test IOU:\", avg_iou)\n",
        "\n",
        "  def display_results(self):\n",
        "    \"\"\" Plots the training/testing losses and IOUs over the training cycle\n",
        "        and prints the final epoch's average loss, IOU, and training time.\n",
        "    \"\"\"\n",
        "    final_loss = self.testing_losses[-1]\n",
        "    final_iou = self.testing_ious[-1]\n",
        "    train_time = round(self.train_time, 2)\n",
        "\n",
        "    plot_train_test(self.training_losses, self.testing_losses, \"Cross Entropy Loss\")\n",
        "    plot_train_test(self.training_ious, self.testing_ious, \"IOU\")\n",
        "    print(f\"Final test loss (Unsupervised Average Pixel) is {final_loss}\")\n",
        "    print(f\"Final test IOU is {final_iou}\")\n",
        "    print(f\"\\nTotal training time is {train_time} seconds\\n\")\n",
        "\n",
        "  def get_trained_model(self):\n",
        "    \"\"\" Returns the trained U-Net Model.\n",
        "    \"\"\"\n",
        "    return self.model\n",
        "\n",
        "  def run_loop(self):\n",
        "    \"\"\" Trains and tests for a given number of epochs. Then, displays the results\n",
        "        of the training.\n",
        "    \"\"\"\n",
        "    for epoch in range(self.EPOCHS):\n",
        "      do_print = epoch % 50 == 0\n",
        "      if do_print:\n",
        "        print(f\"Running epoch {epoch + 1} out of {self.EPOCHS}\")\n",
        "      self.train(do_print)\n",
        "      self.test(do_print)\n",
        "    self.display_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkwwq11TAhgH",
        "outputId": "0ba55598-7f48-4d87-fdc4-f9ef7322b0bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 825 data points\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "image_file_path = f'{base_dir}/Data/combined_alphas.npz'\n",
        "image_data = np.load(image_file_path)\n",
        "\n",
        "# Get the total number of data points\n",
        "total_data_points = len(image_data['data'])\n",
        "\n",
        "# extract data\n",
        "loaded_data = image_data['data']\n",
        "loaded_labels = image_data['labels']\n",
        "alpha1s = image_data['alpha1s']\n",
        "alpha2s = image_data['alpha2s']\n",
        "\n",
        "print(f\"Loaded {len(alpha1s)} data points\")\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test, alpha1s_train, alpha1s_test, alpha2s_train, alpha2s_test = \\\n",
        "    train_test_split(loaded_data, loaded_labels, alpha1s, alpha2s, test_size=0.2, random_state=42)\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = PerlinNoiseDataset(X_train, y_train)\n",
        "train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataset = PerlinNoiseDataset(X_test, y_test)\n",
        "test_dl = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lZtLuDDcN4s"
      },
      "outputs": [],
      "source": [
        "def run_model(model, model_name, euc_coef=0, ce_coef=1, save_model=False):\n",
        "  print(model_name)\n",
        "  model_runner = ModelRunner(model, train_dl, test_dl, epochs=70, eucdist_coef=euc_coef, ce_coef=ce_coef)\n",
        "  model_runner.run_loop()\n",
        "  trained_model = model_runner.get_trained_model()\n",
        "  do_save = \"\"\n",
        "  if save_model:\n",
        "    torch.save(trained_model.state_dict(), f'{base_dir}/Models/{model_name}.pth')\n",
        "\n",
        "    #write results to csv file\n",
        "    final_loss = model_runner.testing_losses[-1]\n",
        "    final_iou = model_runner.testing_ious[-1]\n",
        "    train_time = round(model_runner.train_time, 2)\n",
        "    file_path = f'{base_dir}/Results/quantitative_results_pixelaveraging.csv'\n",
        "    df = pd.read_csv(file_path)\n",
        "    mask = df['Model Name'] == model_name\n",
        "    if mask.any():\n",
        "        df.loc[mask, ['Final Test Cross Entropy Loss', 'Final Test IOU', 'Training Time (s)']] = [final_loss, final_iou, train_time]\n",
        "    else:\n",
        "        df.loc[len(df)] = [model_name, final_loss, final_iou, train_time]\n",
        "    df.to_csv(file_path, index=False)\n",
        "    do_save = model_name\n",
        "\n",
        "  #plot losses/ious and save\n",
        "  plot_train_test(model_runner.training_losses, model_runner.testing_losses, \"Unsupervised Pixel Averaging Loss\", do_save)\n",
        "  plot_train_test(model_runner.training_ious, model_runner.testing_ious, \"IOU\", do_save)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supervised Training"
      ],
      "metadata": {
        "id": "4YUDOMraQrw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet()\n",
        "run_model(model, \"UNet_losscoef_1e-3\", euc_coef=.001, save_model=True)\n",
        "model = UNet()\n",
        "run_model(model, \"UNet_losscoef_1e-2\", euc_coef=.01, save_model=True)\n",
        "model = UNet()\n",
        "run_model(model, \"UNet_losscoef_1e-1\", euc_coef=.1, save_model=True)\n",
        "model = UNet()\n",
        "run_model(model, \"UNet_losscoef_1\", euc_coef=1, save_model=True)\n",
        "model = UNet()\n",
        "run_model(model, \"UNet_losscoef_1e1\", euc_coef=10, save_model=True)\n",
        "model = UNet()\n",
        "run_model(model, \"UNet_losscoef_1e2\", euc_coef=100, save_model=True)"
      ],
      "metadata": {
        "id": "Mi5uWjg0Q4Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsupervised Training"
      ],
      "metadata": {
        "id": "gjJ87d6NQ0PE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "7aYstCgQcng9",
        "outputId": "43218ef6-2ca5-40c0-a5ca-9a279a68bf57",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet_unsupervised_averagepixel_loss\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4b7818614d3f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"UNet_unsupervised_averagepixel_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-5377feaf23dc>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, model_name, loss_coef, save_model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_coef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mmodel_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-3626dd41aa53>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, train_dl, test_dl, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOSS_FUNC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnsupervisedAveragePixelLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     43\u001b[0m                         \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforeach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapturable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapturable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                         differentiable=differentiable, fused=fused)\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallowed_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcode_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcode_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvert_frame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moutput_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOutputGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreplay_record\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExecutionRecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInstructionTranslator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpeculationLog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     88\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariableTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphArg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrackedFake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariableBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_fx_proxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNNModuleVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m from .variables.tensor import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/variables/builder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[0;31m# Used by shape guard computation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdataclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1578\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTrackedFake\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1579\u001b[0m     \u001b[0mfake\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFakeTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymInt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m     \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36mdataclass\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[0;31m# We're called as @dataclass without parens.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         return _process_class(cls, init, repr, eq, order, unsafe_hash,\n\u001b[0m\u001b[1;32m   1176\u001b[0m                               frozen, match_args, kw_only, slots)\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36m_process_class\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatch_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# I could probably compute this once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m         _set_new_attribute(cls, '__match_args__',\n\u001b[0m\u001b[1;32m   1098\u001b[0m                            tuple(f.name for f in std_init_fields))\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36m_set_new_attribute\u001b[0;34m(cls, name, value)\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m     \u001b[0m_set_qualname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36m_set_qualname\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;31m# Ensure that the functions returned from _create_fn uses the proper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;31m# __qualname__ (the class they belong to).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunctionType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{cls.__qualname__}.{value.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = UNet()\n",
        "run_model(model, \"UNet_unsupervised_averagepixel_loss\", euc_coef=1, ce_coef=0, save_model=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dxWBEh_pu8a"
      },
      "source": [
        "Code to Test with Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgibZw3wAlGB"
      },
      "outputs": [],
      "source": [
        "def make_plots(data, labels, trained_model, alpha1s, alpha2s, counter=0, model_name=\"\"):\n",
        "    y_pred = trained_model(data.unsqueeze(1))\n",
        "    #_, y_pred = torch.max(y_pred, 1) #turn into segmentation mask\n",
        "    for i in range(len(data)):\n",
        "        d = data[i]\n",
        "        l = labels[i]\n",
        "        y = y_pred[i]\n",
        "        _, y = torch.max(y, 0)\n",
        "        alpha1 = alpha1s[i]\n",
        "        alpha2 = alpha2s[i]\n",
        "\n",
        "        print(f\"alpha1 = {alpha1}, alpha2 = {alpha2}\")\n",
        "        #print(d.min(), d.max())\n",
        "\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "        # Display the original image\n",
        "        d = d.cpu().numpy()\n",
        "        axes[0].imshow(d, cmap='gray')\n",
        "        axes[0].set_title('Original Image')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        # Display prediction\n",
        "        # y = (y >= 0.5).float()\n",
        "        y = y.squeeze(0).cpu().detach().numpy()\n",
        "        axes[1].imshow(y, cmap='gray')#, vmin=0, vmax=1)\n",
        "        axes[1].set_title('Pred')\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        # Display Label\n",
        "        l = l.cpu().numpy()\n",
        "        axes[2].imshow(l, cmap='gray')\n",
        "        axes[2].set_title('Label')\n",
        "        axes[2].axis('off')\n",
        "\n",
        "        if model_name:\n",
        "          plt.savefig(f'{base_dir}/Results/Segmentations/{model_name}_Validation_{counter}.png')\n",
        "          plt.show()\n",
        "          plt.clf()\n",
        "        plt.show()\n",
        "\n",
        "def show_results(trained_model, model_name=\"\"):\n",
        "    BATCH_SIZE = 8\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    n_images = 5\n",
        "\n",
        "    train_dataset = PerlinNoiseDataset(X_train[:n_images], y_train[:n_images])\n",
        "    train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_dataset = PerlinNoiseDataset(X_test[:n_images], y_test[:n_images])\n",
        "    test_dl = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # load pretrained model\n",
        "    trained_model = trained_model.to(DEVICE)\n",
        "    trained_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # print(\"Training Examples:\")\n",
        "        # for data, labels in train_dl:\n",
        "        #     make_plots(data, labels, trained_model, alpha1s_train[:n_images], alpha2s_train[:n_images])\n",
        "\n",
        "        print(\"\\n\\nTesting Examples:\")\n",
        "        counter=1\n",
        "        for data, labels in test_dl:\n",
        "            make_plots(data, labels, trained_model, alpha1s_test[:n_images], alpha2s_test[:n_images], counter, model_name)\n",
        "            counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, model_name, test_function):\n",
        "  print(f'{model_name}:')\n",
        "  model.load_state_dict(torch.load(f'{base_dir}/Models/{model_name}.pth', map_location=torch.device(DEVICE)))\n",
        "  test_function(model, model_name)\n",
        "\n",
        "model = UNet()\n",
        "test_model(model, \"UNet_losscoef_1e-3\", show_results)\n",
        "model = UNet()\n",
        "test_model(model, \"UNet_losscoef_1e-2\", show_results)\n",
        "model = UNet()\n",
        "test_model(model, \"UNet_losscoef_1e-1\", show_results)\n",
        "model = UNet()\n",
        "test_model(model, \"UNet_losscoef_1\", show_results)\n",
        "model = UNet()\n",
        "test_model(model, \"UNet_losscoef_1e1\", show_results)\n",
        "model = UNet()\n",
        "test_model(model, \"UNet_losscoef_1e2\", show_results)\n",
        "\n",
        "\n",
        "model = UNet()\n",
        "test_model(model, \"UNet_unsupervised_averagepixel_loss\", show_results)"
      ],
      "metadata": {
        "id": "UGUUa_WBTlIb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}